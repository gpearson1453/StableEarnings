# Phase 1
In Phase 1, all relevant files are downloaded from Equibase, which are provided in PDF format. These files are reformatted by numbering the PDFs and creating corresponding files to hold their extracted text. The extracted text is then analyzed to retrieve all relevant information, including race results and horse profiles. This data is consolidated into a comprehensive CSV file, which will serve as the foundation for further analysis in the project.

---

## Folders

### `Phase 1/pdf_files`
`pdf_files` contains subfolders organized by month and year (e.g., 01-2020). Each subfolder holds the necessary PDF files for the project. These PDFs have been renamed from their original filenames and sequentially numbered to ensure easier reference and usage during processing.

### `Phase 1/testing_files`
`testing_files` is intended to hold copies of text files that present issues during processing. It allows for testing and debugging these files independently from the rest of the dataset. By isolating problematic files, it becomes easier to identify and resolve specific issues without impacting the overall workflow.

### `Phase 1/text_files`
`text_files` contains all the text files extracted from the PDF files using the `reformatRaceFiles` script.

### `Phase 1/zipped_originals`
`zipped_originals` holds all the original PDF files, preserved with their original filenames. The files are stored in no-loss compressed folders, each named identically to the corresponding folder in the `pdf_files` directory. This ensures that the original PDFs remain accessible while maintaining a clear organizational structure.

---

## Python Files

### `Phase 1/findMissOrDup.py`
`findMissOrDup.py` checks for missing or duplicate files in a folder.

This script searches for duplicate race files in a folder by looking for duplicate entry pairs ('race_id' and 'horse_name') in `select_race_data.xlsx`, the Excel file generated by `processSelectToExcel.py`, after the script has been run with that folder. It searches for missing files by extracting dates and locations from the provided text block, which must be manually created using text on Equibase for that month, and looking through the Excel file to ensure that those values appear. Finally, it prints out the information of missing and duplicate files, if any are found.

Steps:
- Creates a pandas DataFrame to parse the data in the Excel file.
- Identifies duplicate rows that have the same 'race_id' and 'horse_name'.
- Verifies the presence of specific date and track combinations in the dataset using a text block containing all race locations and dates for a certain month.
- Prints missing entries and duplicate information for review.

### `Phase 1/getHorses.py`
`getHorses.py` processes horse-specific data extracted from race text segments.

This script defines functions to parse text segments for details about horses participating in races. It extracts information like program numbers, horse names, jockeys, weights, odds, trainers, owners, and performance figures. It ensures accurate data extraction even with varied input formats and edge cases like missing or malformed data.

Steps:
- Extract the Past Performance Running Line Preview (PPRLP) block from the text and call `processPPRLP.py` to get performance line data.
- Parse the text for jockey, trainer, and owner details.
- Process performance figures for each horse, including positions and distances.
- Compile all extracted details into structured dictionaries for each horse.

### `Phase 1/getRaces.py`
`getRaces.py` extracts and processes race-related data from a text segment.

This script defines functions to process a text segment containing race information. It extracts metadata such as race details, weather, surface, times, and more. It also integrates horse-specific data by calling the `getHorses` function from `getHorses.py` and calculates positional factors for horses based on their performance.

Steps:
- Parse the input text segment to extract general race information (e.g., date, location, weather).
- Identify and process specific data such as fractional and split times, surface type, and distance.
- Validate the race type to ensure it is supported (e.g., Thoroughbred or Quarter Horse).
- Call the getHorses function to retrieve horse-specific data.
- Calculate positional factors for horses based on their relative performance.
- Combine common race data with horse-specific data into a structured output.

### `Phase 1/mappings.py`
`mappings.py` contains distance conversions and horse race type patterns.

This file contains a distance conversion dictionary (from text versions to decimal values) and a list of horse race type patterns, which are both used in `getRaces.py`.

### `Phase 1/processAllToCSV.py`
`processAllToCSV.py` extracts race data from text files and compiles it into a CSV file.

This script processes folders of text files derived from race files, extracts relevant race information from each file, and saves the data to an output CSV file, `all_race_data.csv`. It skips files or segments that are invalid, contain cancellation messages, or have an unsupported race type.

Steps:
- Splits the text of each file into manageable segments using a predefined delimiter.
- Skips segments with cancellation messages or invalid race types.
- Extracts race data using the `getRaces` function and appends file-level information.
- Compiles extracted data into a structured format, with sorting and column reordering.
- Writes the processed data to `all_race_data.csv`.
- Logs files that contain no valid data for further review.

### `Phase 1/processPPRLP.py`
`processPPRLP.py` processes the Past Performance Running Line Preview (PPRLP) text block.

This script defines a function to extract structured horse performance data from the PPRLP block. It splits the input text into headers and values, processes inconsistencies, and returns the data in a structured format.

Steps:
- Replace problematic header names to ensure consistent formatting.
- Remove excessive whitespace and merge split lines.
- Split the text into headers and values based on the "Fin" delimiter.
- Address errors caused by unconventional formatting of horse names or numerical values.
- Return the processed values as a list of lists, where each list represents a horse's data.

### `Phase 1/processSelectToExcel.py`
`processSelectToExcel.py` extracts selected race data from text files and compiles it into an Excel file.

This script processes a folder of text files derived from race files, extracts relevant race information from each file, and saves the data to an output Excel file, `select_race_data.xlsx`. It skips files or segments that are invalid, contain cancellation messages, or have an unsupported race type.

Steps:
- Splits the text of each file into manageable segments using a predefined delimiter.
- Skips segments with cancellation messages or invalid race types.
- Extracts race data using the getRaces function and appends file-level information.
- Compiles extracted data into a structured format, with sorting and column reordering.
- Writes the processed data to `select_race_data.xlsx` with frozen panes for improved readability.
- Logs files that contain no valid data for further review.

### `Phase 1/reformatRaceFiles.py`
`reformatRaceFiles.py` renames race PDF files sequentially and extracts their text content.

This script processes folders of PDF files, renaming them in a sequential order based on their creation time and extracting their text content into corresponding text files. The extracted text files are saved in a folder named after the original folder where the PDF files were found.

Steps:
- Iterates through folders within a specified PDF directory.
- Renames PDF files sequentially, ensuring unique names even in case of conflicts.
- Extracts text content from each PDF and saves it as a text file in the corresponding output folder.

### `Phase 1/replaceBadNames.py`
`replaceBadNames.py` replaces specific strings in text files within a folder hierarchy.

This script processes all text files in a specified folder (and its subfolders) and replaces occurrences of a target string with a replacement string. It supports multi-threaded processing for improved performance.

Steps:
- Iterates through a folder and its subfolders to locate all `.txt` files.
- Replaces the target string with the replacement string in each file's content.
- Provides two modes: replacing specific string pairs or standardizing names by replacing spaces with hyphens.

---

## Other Files

### `Phase 1/all_race_data.csv`
This CSV file is generated by `processAllToCSV.py` and contains all the data extracted from the PDF files. It aggregates all relevant race and horse information into one comprehensive dataset.

### `Phase 1/select_race_data.xlsx`
This Excel file is created by `processSelectToExcel.py` to allow for easy examination of data from a specific folder, enabling a more focused review compared to the comprehensive CSV file.
